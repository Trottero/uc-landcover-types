{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: ((64, 64, 13), ()), types: (tf.float32, tf.int64)>\n",
      "<class 'numpy.ndarray'> <class 'numpy.int64'> 8\n",
      "FeaturesDict({\n",
      "    'filename': Text(shape=(), dtype=tf.string),\n",
      "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
      "    'sentinel2': Tensor(shape=(64, 64, 13), dtype=tf.float32),\n",
      "})\n",
      "Train test split sizes: \n",
      "Train:  21600\n",
      "Test:  5400\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Download tensorflow eurosat dataset\n",
    "(train, test), info = tfds.load('eurosat/all', split=['train[:80%]', 'train[80%:]'], as_supervised=True, with_info=True)\n",
    "assert isinstance(train, tf.data.Dataset)\n",
    "print(train)\n",
    "\n",
    "sample = train.take(1)\n",
    "\n",
    "\n",
    "for image, label in tfds.as_numpy(sample):\n",
    "    print(type(image), type(label), label)\n",
    "\n",
    "print(info.features)\n",
    "\n",
    "print('Train test split sizes: ')\n",
    "print('Train: ', len(train))\n",
    "print('Test: ', len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(64, 64, 13), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = (64, 64, 13)\n",
    "\n",
    "train.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Niels\\.virtualenvs\\uc-landcover-types--9lkH9oZ\\lib\\site-packages\\keras\\applications\\resnet.py:135: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 13 input channels.\n",
      "  input_shape = imagenet_utils.obtain_input_shape(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64, 64, 13)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 70, 70, 13)   0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 32, 32, 64)   40832       ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 32, 32, 64)   256         ['conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 32, 32, 64)   0           ['conv1_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 34, 34, 64)   0           ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 16, 16, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 16, 16, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 16, 16, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 16, 16, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 16, 16, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 16, 16, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 16, 16, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 16, 16, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 16, 16, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 16, 16, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 16, 16, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 16, 16, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 16, 16, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 16, 16, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 16, 16, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 16, 16, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 16, 16, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 16, 16, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 16, 16, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 8, 8, 128)    32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 8, 8, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 8, 8, 512)    131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 8, 8, 512)    0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 8, 8, 512)    0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 8, 8, 128)    65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 8, 8, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 8, 8, 512)    0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 8, 8, 512)    0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 8, 8, 128)    65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 8, 8, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 8, 8, 512)    0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 8, 8, 512)    0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 8, 8, 128)    65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 8, 8, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 8, 8, 128)   0           ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 8, 8, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 8, 8, 512)    0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 8, 8, 512)    0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 4, 4, 256)    131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 4, 4, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                                                  'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block1_out[0][0]',       \n",
      "                                                                  'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block2_out[0][0]',       \n",
      "                                                                  'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block3_out[0][0]',       \n",
      "                                                                  'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block4_out[0][0]',       \n",
      "                                                                  'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block5_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 4, 4, 256)    262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 4, 4, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 4, 4, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 4, 4, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 4, 4, 1024)   0           ['conv4_block5_out[0][0]',       \n",
      "                                                                  'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 4, 4, 1024)   0           ['conv4_block6_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 2, 2, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 2, 2, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 2, 2, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 2, 2, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 2, 2, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 2, 2, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 2, 2, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 2, 2, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 2, 2, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 2, 2, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " max_pool (GlobalMaxPooling2D)  (None, 2048)         0           ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,619,072\n",
      "Trainable params: 23,565,952\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top=False, weights=None, input_shape=input_dim, pooling='max', classes=10\n",
    ")\n",
    "\n",
    "keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 1: Use a batchsize schedule\n",
    "On our computers this runs out of memory, as a tensor of size 3200 * 70 * 70 * 13 already requires a sie of 1.6GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_SCHEDULER = False\n",
    "\n",
    "if BATCH_SIZE_SCHEDULER:\n",
    "    batch_sizes = [128, 640, 3200, 16_000]\n",
    "    epochs = [60, 60, 40, 40]\n",
    "    hist = None\n",
    "    for epoch_set, batch_size in zip(epochs, batch_sizes):\n",
    "        h1 = model.fit(train.batch(batch_size), epochs=epoch_set, validation_data=test.batch(batch_size))\n",
    "        if hist is None:\n",
    "            hist = pd.DataFrame(h1.history)\n",
    "            print(hist.head())\n",
    "        else:\n",
    "            hist = hist.append(pd.DataFrame(h1.history))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2: Use a custom learning rate scheduler\n",
    "This is known to be significantly slower, but atleast it is possible to train the network on our computers this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Niels\\.virtualenvs\\uc-landcover-types--9lkH9oZ\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 30s 241ms/step - loss: 3.0807 - accuracy: 0.2748 - val_loss: 6.2186 - val_accuracy: 0.1211 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "85/85 [==============================] - 20s 216ms/step - loss: 1.5019 - accuracy: 0.5150 - val_loss: 6.6219 - val_accuracy: 0.0885 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "85/85 [==============================] - 19s 220ms/step - loss: 1.3995 - accuracy: 0.5465 - val_loss: 4.6653 - val_accuracy: 0.3178 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "85/85 [==============================] - 19s 224ms/step - loss: 1.1300 - accuracy: 0.6840 - val_loss: 7.1782 - val_accuracy: 0.0509 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "85/85 [==============================] - 19s 224ms/step - loss: 1.4768 - accuracy: 0.5508 - val_loss: 6.1846 - val_accuracy: 0.2146 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "85/85 [==============================] - 19s 218ms/step - loss: 1.8774 - accuracy: 0.3994 - val_loss: 7.5262 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "85/85 [==============================] - 19s 218ms/step - loss: 1.4024 - accuracy: 0.5335 - val_loss: 2.6581 - val_accuracy: 0.3331 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "85/85 [==============================] - 19s 214ms/step - loss: 1.1862 - accuracy: 0.6633 - val_loss: 2.3225 - val_accuracy: 0.4431 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "85/85 [==============================] - 20s 224ms/step - loss: 1.0493 - accuracy: 0.7001 - val_loss: 1.9495 - val_accuracy: 0.5037 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "85/85 [==============================] - 19s 223ms/step - loss: 1.3475 - accuracy: 0.5190 - val_loss: 7.1701 - val_accuracy: 0.0339 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "85/85 [==============================] - 19s 220ms/step - loss: 1.8218 - accuracy: 0.2903 - val_loss: 6.3829 - val_accuracy: 0.0267 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "85/85 [==============================] - 19s 221ms/step - loss: 1.6288 - accuracy: 0.3595 - val_loss: 3.5139 - val_accuracy: 0.2244 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "85/85 [==============================] - 19s 219ms/step - loss: 1.3832 - accuracy: 0.5292 - val_loss: 1.4444 - val_accuracy: 0.5791 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "85/85 [==============================] - 20s 226ms/step - loss: 1.3977 - accuracy: 0.5294 - val_loss: 2.2424 - val_accuracy: 0.4461 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "85/85 [==============================] - 20s 226ms/step - loss: 1.3937 - accuracy: 0.5394 - val_loss: 2.1832 - val_accuracy: 0.5343 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "85/85 [==============================] - 19s 215ms/step - loss: 1.0906 - accuracy: 0.6599 - val_loss: 1.1454 - val_accuracy: 0.6526 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "85/85 [==============================] - 19s 220ms/step - loss: 1.3381 - accuracy: 0.5819 - val_loss: 7.6517 - val_accuracy: 0.0169 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "85/85 [==============================] - 19s 219ms/step - loss: 1.4741 - accuracy: 0.4654 - val_loss: 2.9021 - val_accuracy: 0.3667 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "85/85 [==============================] - 20s 226ms/step - loss: 1.1379 - accuracy: 0.5810 - val_loss: 1.2280 - val_accuracy: 0.5663 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "85/85 [==============================] - 20s 224ms/step - loss: 1.7183 - accuracy: 0.4775 - val_loss: 7.3646 - val_accuracy: 0.0294 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "85/85 [==============================] - 19s 218ms/step - loss: 1.7242 - accuracy: 0.2603 - val_loss: 2.5608 - val_accuracy: 0.2098 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "85/85 [==============================] - 19s 215ms/step - loss: 1.4777 - accuracy: 0.3795 - val_loss: 1.5199 - val_accuracy: 0.3978 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "85/85 [==============================] - 20s 217ms/step - loss: 1.2899 - accuracy: 0.5266 - val_loss: 1.6544 - val_accuracy: 0.5446 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "85/85 [==============================] - 20s 227ms/step - loss: 1.1202 - accuracy: 0.6253 - val_loss: 1.4379 - val_accuracy: 0.5093 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "85/85 [==============================] - 20s 228ms/step - loss: 1.0790 - accuracy: 0.6410 - val_loss: 2.0612 - val_accuracy: 0.5220 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "85/85 [==============================] - 19s 217ms/step - loss: 1.0136 - accuracy: 0.6621 - val_loss: 2.7828 - val_accuracy: 0.4241 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "85/85 [==============================] - 19s 215ms/step - loss: 1.2505 - accuracy: 0.6294 - val_loss: 1.4508 - val_accuracy: 0.5730 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "85/85 [==============================] - 19s 214ms/step - loss: 1.0078 - accuracy: 0.6994 - val_loss: 1.0717 - val_accuracy: 0.7044 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "85/85 [==============================] - 20s 228ms/step - loss: 1.3421 - accuracy: 0.6523 - val_loss: 10.2530 - val_accuracy: 0.0030 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "85/85 [==============================] - 20s 227ms/step - loss: 1.0260 - accuracy: 0.7096 - val_loss: 2.8558 - val_accuracy: 0.5226 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "85/85 [==============================] - 19s 220ms/step - loss: 0.9472 - accuracy: 0.7142 - val_loss: 1.6669 - val_accuracy: 0.5450 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "85/85 [==============================] - 19s 217ms/step - loss: 0.8817 - accuracy: 0.7406 - val_loss: 1.8436 - val_accuracy: 0.5417 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "85/85 [==============================] - 19s 215ms/step - loss: 0.8751 - accuracy: 0.7239 - val_loss: 3.3649 - val_accuracy: 0.3467 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "85/85 [==============================] - 20s 225ms/step - loss: 0.7883 - accuracy: 0.7651 - val_loss: 2.5675 - val_accuracy: 0.4778 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "85/85 [==============================] - 20s 225ms/step - loss: 0.7238 - accuracy: 0.7988 - val_loss: 1.7891 - val_accuracy: 0.6111 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "85/85 [==============================] - 19s 223ms/step - loss: 0.7820 - accuracy: 0.7833 - val_loss: 1.5575 - val_accuracy: 0.6459 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "85/85 [==============================] - 19s 218ms/step - loss: 0.6666 - accuracy: 0.8137 - val_loss: 0.7070 - val_accuracy: 0.8039 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "85/85 [==============================] - 19s 215ms/step - loss: 0.6755 - accuracy: 0.8226 - val_loss: 5.1521 - val_accuracy: 0.3374 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "85/85 [==============================] - 20s 224ms/step - loss: 0.8149 - accuracy: 0.7760 - val_loss: 2.1007 - val_accuracy: 0.6089 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "85/85 [==============================] - 20s 227ms/step - loss: 0.6835 - accuracy: 0.8163 - val_loss: 4.5130 - val_accuracy: 0.4889 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "85/85 [==============================] - 20s 222ms/step - loss: 0.6932 - accuracy: 0.8141 - val_loss: 6.5501 - val_accuracy: 0.3383 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "85/85 [==============================] - 19s 220ms/step - loss: 0.8002 - accuracy: 0.7598 - val_loss: 2.7011 - val_accuracy: 0.5656 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "85/85 [==============================] - 19s 221ms/step - loss: 0.8830 - accuracy: 0.7209 - val_loss: 4.5002 - val_accuracy: 0.3996 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "85/85 [==============================] - 20s 222ms/step - loss: 0.7009 - accuracy: 0.7430 - val_loss: 1.1357 - val_accuracy: 0.6448 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "85/85 [==============================] - 19s 222ms/step - loss: 1.0019 - accuracy: 0.6927 - val_loss: 3.1712 - val_accuracy: 0.5233 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "85/85 [==============================] - 20s 222ms/step - loss: 1.0250 - accuracy: 0.6915 - val_loss: 2.2542 - val_accuracy: 0.5072 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "85/85 [==============================] - 19s 220ms/step - loss: 0.8079 - accuracy: 0.7563 - val_loss: 1.1035 - val_accuracy: 0.6622 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "85/85 [==============================] - 19s 220ms/step - loss: 0.7258 - accuracy: 0.7969 - val_loss: 1.6772 - val_accuracy: 0.6320 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "85/85 [==============================] - 19s 217ms/step - loss: 1.1310 - accuracy: 0.6613 - val_loss: 2.5143 - val_accuracy: 0.4865 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "85/85 [==============================] - 20s 228ms/step - loss: 0.9341 - accuracy: 0.7214 - val_loss: 7.4175 - val_accuracy: 0.1280 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "85/85 [==============================] - 20s 226ms/step - loss: 0.9047 - accuracy: 0.7224 - val_loss: 2.3601 - val_accuracy: 0.5074 - lr: 2.0000e-04\n",
      "Epoch 52/200\n",
      "85/85 [==============================] - 19s 220ms/step - loss: 0.8019 - accuracy: 0.7638 - val_loss: 0.8000 - val_accuracy: 0.7576 - lr: 2.0000e-04\n",
      "Epoch 53/200\n",
      "85/85 [==============================] - 19s 220ms/step - loss: 0.7065 - accuracy: 0.7994 - val_loss: 1.1183 - val_accuracy: 0.6222 - lr: 2.0000e-04\n",
      "Epoch 54/200\n",
      "85/85 [==============================] - 19s 221ms/step - loss: 0.7166 - accuracy: 0.8024 - val_loss: 0.9867 - val_accuracy: 0.7054 - lr: 2.0000e-04\n",
      "Epoch 55/200\n",
      "85/85 [==============================] - 19s 223ms/step - loss: 0.7089 - accuracy: 0.8081 - val_loss: 2.0213 - val_accuracy: 0.5850 - lr: 2.0000e-04\n",
      "Epoch 56/200\n",
      "85/85 [==============================] - 20s 225ms/step - loss: 0.8880 - accuracy: 0.7218 - val_loss: 0.8674 - val_accuracy: 0.6793 - lr: 2.0000e-04\n",
      "Epoch 57/200\n",
      "85/85 [==============================] - 19s 216ms/step - loss: 0.7231 - accuracy: 0.7410 - val_loss: 0.9459 - val_accuracy: 0.6539 - lr: 2.0000e-04\n",
      "Epoch 58/200\n",
      "85/85 [==============================] - 19s 220ms/step - loss: 1.0719 - accuracy: 0.6728 - val_loss: 0.9720 - val_accuracy: 0.6530 - lr: 2.0000e-04\n",
      "Epoch 59/200\n",
      "85/85 [==============================] - 19s 220ms/step - loss: 0.7848 - accuracy: 0.7447 - val_loss: 0.8113 - val_accuracy: 0.6804 - lr: 2.0000e-04\n",
      "Epoch 60/200\n",
      "85/85 [==============================] - 20s 223ms/step - loss: 0.7783 - accuracy: 0.7472 - val_loss: 0.8703 - val_accuracy: 0.7574 - lr: 2.0000e-04\n",
      "Epoch 61/200\n",
      "85/85 [==============================] - 20s 229ms/step - loss: 0.7218 - accuracy: 0.7731 - val_loss: 0.7811 - val_accuracy: 0.7343 - lr: 2.0000e-04\n",
      "Epoch 62/200\n",
      "85/85 [==============================] - 19s 221ms/step - loss: 0.6657 - accuracy: 0.7816 - val_loss: 0.6006 - val_accuracy: 0.7719 - lr: 2.0000e-04\n",
      "Epoch 63/200\n",
      "85/85 [==============================] - 19s 221ms/step - loss: 0.6234 - accuracy: 0.7968 - val_loss: 0.6878 - val_accuracy: 0.8004 - lr: 2.0000e-04\n",
      "Epoch 64/200\n",
      "85/85 [==============================] - 19s 218ms/step - loss: 0.6789 - accuracy: 0.7788 - val_loss: 0.8995 - val_accuracy: 0.6111 - lr: 2.0000e-04\n",
      "Epoch 65/200\n",
      "85/85 [==============================] - 20s 223ms/step - loss: 0.7115 - accuracy: 0.7013 - val_loss: 0.8640 - val_accuracy: 0.6020 - lr: 2.0000e-04\n",
      "Epoch 66/200\n",
      "85/85 [==============================] - 20s 224ms/step - loss: 0.6482 - accuracy: 0.7275 - val_loss: 0.7472 - val_accuracy: 0.6865 - lr: 2.0000e-04\n",
      "Epoch 67/200\n",
      "85/85 [==============================] - 19s 224ms/step - loss: 0.6117 - accuracy: 0.7777 - val_loss: 0.6075 - val_accuracy: 0.7996 - lr: 2.0000e-04\n",
      "Epoch 68/200\n",
      "85/85 [==============================] - 19s 213ms/step - loss: 0.6376 - accuracy: 0.8006 - val_loss: 0.7156 - val_accuracy: 0.8015 - lr: 2.0000e-04\n",
      "Epoch 69/200\n",
      "85/85 [==============================] - 19s 214ms/step - loss: 0.5686 - accuracy: 0.8461 - val_loss: 0.7709 - val_accuracy: 0.7854 - lr: 2.0000e-04\n",
      "Epoch 70/200\n",
      "85/85 [==============================] - 20s 219ms/step - loss: 0.5310 - accuracy: 0.8656 - val_loss: 0.5635 - val_accuracy: 0.8494 - lr: 2.0000e-04\n",
      "Epoch 71/200\n",
      "85/85 [==============================] - 20s 226ms/step - loss: 0.7667 - accuracy: 0.7904 - val_loss: 0.9240 - val_accuracy: 0.7602 - lr: 2.0000e-04\n",
      "Epoch 72/200\n",
      "85/85 [==============================] - 19s 219ms/step - loss: 0.5872 - accuracy: 0.8470 - val_loss: 0.5763 - val_accuracy: 0.8583 - lr: 2.0000e-04\n",
      "Epoch 73/200\n",
      "85/85 [==============================] - 19s 214ms/step - loss: 1.1423 - accuracy: 0.7197 - val_loss: 2.4054 - val_accuracy: 0.5383 - lr: 2.0000e-04\n",
      "Epoch 74/200\n",
      "85/85 [==============================] - 19s 214ms/step - loss: 0.7616 - accuracy: 0.7714 - val_loss: 0.7636 - val_accuracy: 0.8087 - lr: 2.0000e-04\n",
      "Epoch 75/200\n",
      "85/85 [==============================] - 19s 217ms/step - loss: 0.6683 - accuracy: 0.7989 - val_loss: 0.7184 - val_accuracy: 0.7817 - lr: 2.0000e-04\n",
      "Epoch 76/200\n",
      "85/85 [==============================] - 20s 220ms/step - loss: 0.5769 - accuracy: 0.8374 - val_loss: 0.6407 - val_accuracy: 0.8081 - lr: 2.0000e-04\n",
      "Epoch 77/200\n",
      "85/85 [==============================] - 19s 222ms/step - loss: 0.5186 - accuracy: 0.8589 - val_loss: 0.5446 - val_accuracy: 0.8522 - lr: 2.0000e-04\n",
      "Epoch 78/200\n",
      "85/85 [==============================] - 19s 218ms/step - loss: 0.4784 - accuracy: 0.8689 - val_loss: 0.5211 - val_accuracy: 0.8583 - lr: 2.0000e-04\n",
      "Epoch 79/200\n",
      "85/85 [==============================] - 19s 220ms/step - loss: 0.4523 - accuracy: 0.8759 - val_loss: 0.6695 - val_accuracy: 0.8365 - lr: 2.0000e-04\n",
      "Epoch 80/200\n",
      "85/85 [==============================] - 19s 220ms/step - loss: 0.4455 - accuracy: 0.8792 - val_loss: 0.6578 - val_accuracy: 0.8426 - lr: 2.0000e-04\n",
      "Epoch 81/200\n",
      "85/85 [==============================] - 20s 224ms/step - loss: 0.4357 - accuracy: 0.8851 - val_loss: 0.4889 - val_accuracy: 0.8817 - lr: 2.0000e-04\n",
      "Epoch 82/200\n",
      "85/85 [==============================] - 20s 220ms/step - loss: 0.7090 - accuracy: 0.8419 - val_loss: 1.0703 - val_accuracy: 0.7522 - lr: 2.0000e-04\n",
      "Epoch 83/200\n",
      "85/85 [==============================] - 19s 218ms/step - loss: 0.5431 - accuracy: 0.8604 - val_loss: 2.1083 - val_accuracy: 0.5361 - lr: 2.0000e-04\n",
      "Epoch 84/200\n",
      "85/85 [==============================] - 19s 216ms/step - loss: 0.6027 - accuracy: 0.8260 - val_loss: 0.6102 - val_accuracy: 0.8111 - lr: 2.0000e-04\n",
      "Epoch 85/200\n",
      "85/85 [==============================] - 19s 211ms/step - loss: 0.4956 - accuracy: 0.8723 - val_loss: 0.5020 - val_accuracy: 0.8594 - lr: 2.0000e-04\n",
      "Epoch 86/200\n",
      "85/85 [==============================] - 19s 213ms/step - loss: 0.5963 - accuracy: 0.8485 - val_loss: 1.0475 - val_accuracy: 0.7291 - lr: 2.0000e-04\n",
      "Epoch 87/200\n",
      "85/85 [==============================] - 20s 223ms/step - loss: 0.4945 - accuracy: 0.8657 - val_loss: 0.7485 - val_accuracy: 0.7959 - lr: 2.0000e-04\n",
      "Epoch 88/200\n",
      "85/85 [==============================] - 19s 219ms/step - loss: 0.5784 - accuracy: 0.8533 - val_loss: 0.8006 - val_accuracy: 0.8354 - lr: 2.0000e-04\n",
      "Epoch 89/200\n",
      "85/85 [==============================] - 19s 213ms/step - loss: 0.4764 - accuracy: 0.8821 - val_loss: 0.6765 - val_accuracy: 0.8613 - lr: 2.0000e-04\n",
      "Epoch 90/200\n",
      "85/85 [==============================] - 19s 217ms/step - loss: 0.4194 - accuracy: 0.8903 - val_loss: 0.4531 - val_accuracy: 0.8898 - lr: 2.0000e-04\n",
      "Epoch 91/200\n",
      "85/85 [==============================] - 20s 227ms/step - loss: 0.5870 - accuracy: 0.8336 - val_loss: 1.5669 - val_accuracy: 0.6683 - lr: 2.0000e-04\n",
      "Epoch 92/200\n",
      "85/85 [==============================] - 20s 220ms/step - loss: 0.5562 - accuracy: 0.8271 - val_loss: 0.6115 - val_accuracy: 0.8133 - lr: 2.0000e-04\n",
      "Epoch 93/200\n",
      "85/85 [==============================] - 19s 218ms/step - loss: 0.4789 - accuracy: 0.8478 - val_loss: 0.5630 - val_accuracy: 0.8500 - lr: 2.0000e-04\n",
      "Epoch 94/200\n",
      "85/85 [==============================] - 19s 213ms/step - loss: 0.4432 - accuracy: 0.8573 - val_loss: 0.5198 - val_accuracy: 0.8567 - lr: 2.0000e-04\n",
      "Epoch 95/200\n",
      "85/85 [==============================] - 19s 219ms/step - loss: 0.5971 - accuracy: 0.8306 - val_loss: 1.2513 - val_accuracy: 0.7493 - lr: 2.0000e-04\n",
      "Epoch 96/200\n",
      "85/85 [==============================] - 19s 223ms/step - loss: 0.5877 - accuracy: 0.8487 - val_loss: 0.5595 - val_accuracy: 0.8593 - lr: 2.0000e-04\n",
      "Epoch 97/200\n",
      "85/85 [==============================] - 20s 218ms/step - loss: 0.4811 - accuracy: 0.8782 - val_loss: 0.6306 - val_accuracy: 0.8385 - lr: 2.0000e-04\n",
      "Epoch 98/200\n",
      "85/85 [==============================] - 19s 218ms/step - loss: 0.5294 - accuracy: 0.8328 - val_loss: 0.7440 - val_accuracy: 0.7120 - lr: 2.0000e-04\n",
      "Epoch 99/200\n",
      "85/85 [==============================] - 19s 217ms/step - loss: 0.5339 - accuracy: 0.7837 - val_loss: 0.5430 - val_accuracy: 0.8120 - lr: 2.0000e-04\n",
      "Epoch 100/200\n",
      "85/85 [==============================] - 19s 217ms/step - loss: 0.4576 - accuracy: 0.8456 - val_loss: 0.4973 - val_accuracy: 0.8633 - lr: 2.0000e-04\n",
      "Epoch 101/200\n",
      "85/85 [==============================] - 19s 218ms/step - loss: 0.3911 - accuracy: 0.8892 - val_loss: 0.4376 - val_accuracy: 0.8867 - lr: 4.0000e-05\n",
      "Epoch 102/200\n",
      "85/85 [==============================] - 20s 224ms/step - loss: 0.3761 - accuracy: 0.8972 - val_loss: 0.4147 - val_accuracy: 0.8952 - lr: 4.0000e-05\n",
      "Epoch 103/200\n",
      "85/85 [==============================] - 19s 222ms/step - loss: 0.3600 - accuracy: 0.8998 - val_loss: 0.4096 - val_accuracy: 0.8972 - lr: 4.0000e-05\n",
      "Epoch 104/200\n",
      "85/85 [==============================] - 19s 217ms/step - loss: 0.3558 - accuracy: 0.8992 - val_loss: 0.5070 - val_accuracy: 0.8606 - lr: 4.0000e-05\n",
      "Epoch 105/200\n",
      "85/85 [==============================] - 19s 212ms/step - loss: 0.3486 - accuracy: 0.8996 - val_loss: 0.3646 - val_accuracy: 0.9039 - lr: 4.0000e-05\n",
      "Epoch 106/200\n",
      "85/85 [==============================] - 19s 218ms/step - loss: 0.3349 - accuracy: 0.9043 - val_loss: 0.4490 - val_accuracy: 0.8750 - lr: 4.0000e-05\n",
      "Epoch 107/200\n",
      "85/85 [==============================] - 19s 224ms/step - loss: 0.3650 - accuracy: 0.8952 - val_loss: 0.3708 - val_accuracy: 0.9020 - lr: 4.0000e-05\n",
      "Epoch 108/200\n",
      "85/85 [==============================] - 19s 224ms/step - loss: 0.3370 - accuracy: 0.9035 - val_loss: 0.3636 - val_accuracy: 0.9061 - lr: 4.0000e-05\n",
      "Epoch 109/200\n",
      "85/85 [==============================] - 19s 214ms/step - loss: 0.3199 - accuracy: 0.9075 - val_loss: 0.3666 - val_accuracy: 0.9085 - lr: 4.0000e-05\n",
      "Epoch 110/200\n",
      "85/85 [==============================] - 19s 219ms/step - loss: 0.3165 - accuracy: 0.9085 - val_loss: 0.3528 - val_accuracy: 0.9070 - lr: 4.0000e-05\n",
      "Epoch 111/200\n",
      "85/85 [==============================] - 19s 214ms/step - loss: 0.3085 - accuracy: 0.9100 - val_loss: 0.3649 - val_accuracy: 0.9067 - lr: 4.0000e-05\n",
      "Epoch 112/200\n",
      "85/85 [==============================] - 20s 222ms/step - loss: 0.3266 - accuracy: 0.9078 - val_loss: 0.3898 - val_accuracy: 0.9057 - lr: 4.0000e-05\n",
      "Epoch 113/200\n",
      "85/85 [==============================] - 20s 220ms/step - loss: 0.3368 - accuracy: 0.9049 - val_loss: 0.5369 - val_accuracy: 0.8674 - lr: 4.0000e-05\n",
      "Epoch 114/200\n",
      "85/85 [==============================] - 19s 222ms/step - loss: 0.3530 - accuracy: 0.8988 - val_loss: 0.4250 - val_accuracy: 0.8909 - lr: 4.0000e-05\n",
      "Epoch 115/200\n",
      "85/85 [==============================] - 19s 216ms/step - loss: 0.3241 - accuracy: 0.9108 - val_loss: 0.3490 - val_accuracy: 0.9089 - lr: 4.0000e-05\n",
      "Epoch 116/200\n",
      "85/85 [==============================] - 19s 214ms/step - loss: 0.3067 - accuracy: 0.9138 - val_loss: 0.3407 - val_accuracy: 0.9131 - lr: 4.0000e-05\n",
      "Epoch 117/200\n",
      "85/85 [==============================] - 19s 214ms/step - loss: 0.2983 - accuracy: 0.9161 - val_loss: 0.3366 - val_accuracy: 0.9100 - lr: 4.0000e-05\n",
      "Epoch 118/200\n",
      "85/85 [==============================] - 19s 223ms/step - loss: 0.2949 - accuracy: 0.9148 - val_loss: 0.3349 - val_accuracy: 0.9131 - lr: 4.0000e-05\n",
      "Epoch 119/200\n",
      "85/85 [==============================] - 19s 218ms/step - loss: 0.2890 - accuracy: 0.9171 - val_loss: 0.3346 - val_accuracy: 0.9128 - lr: 4.0000e-05\n",
      "Epoch 120/200\n",
      "85/85 [==============================] - 19s 217ms/step - loss: 0.2852 - accuracy: 0.9184 - val_loss: 0.3372 - val_accuracy: 0.9133 - lr: 4.0000e-05\n",
      "Epoch 121/200\n",
      "85/85 [==============================] - 19s 214ms/step - loss: 0.2822 - accuracy: 0.9194 - val_loss: 0.3349 - val_accuracy: 0.9139 - lr: 4.0000e-05\n",
      "Epoch 122/200\n",
      "85/85 [==============================] - 19s 216ms/step - loss: 0.2793 - accuracy: 0.9201 - val_loss: 0.3370 - val_accuracy: 0.9148 - lr: 4.0000e-05\n",
      "Epoch 123/200\n",
      "85/85 [==============================] - 20s 222ms/step - loss: 0.2763 - accuracy: 0.9206 - val_loss: 0.3352 - val_accuracy: 0.9150 - lr: 4.0000e-05\n",
      "Epoch 124/200\n",
      "85/85 [==============================] - 20s 221ms/step - loss: 0.2744 - accuracy: 0.9212 - val_loss: 0.3359 - val_accuracy: 0.9152 - lr: 4.0000e-05\n",
      "Epoch 125/200\n",
      "85/85 [==============================] - 19s 218ms/step - loss: 0.2714 - accuracy: 0.9219 - val_loss: 0.3353 - val_accuracy: 0.9165 - lr: 4.0000e-05\n",
      "Epoch 126/200\n",
      "85/85 [==============================] - 19s 221ms/step - loss: 0.2695 - accuracy: 0.9224 - val_loss: 0.3402 - val_accuracy: 0.9157 - lr: 4.0000e-05\n",
      "Epoch 127/200\n",
      "85/85 [==============================] - 19s 215ms/step - loss: 0.2680 - accuracy: 0.9222 - val_loss: 0.3369 - val_accuracy: 0.9191 - lr: 4.0000e-05\n",
      "Epoch 128/200\n",
      "85/85 [==============================] - 19s 218ms/step - loss: 0.2640 - accuracy: 0.9230 - val_loss: 0.3419 - val_accuracy: 0.9185 - lr: 4.0000e-05\n",
      "Epoch 129/200\n",
      "85/85 [==============================] - 19s 223ms/step - loss: 0.2604 - accuracy: 0.9242 - val_loss: 0.3423 - val_accuracy: 0.9204 - lr: 4.0000e-05\n",
      "Epoch 130/200\n",
      "85/85 [==============================] - 19s 223ms/step - loss: 0.2580 - accuracy: 0.9249 - val_loss: 0.3429 - val_accuracy: 0.9217 - lr: 4.0000e-05\n",
      "Epoch 131/200\n",
      "85/85 [==============================] - 19s 216ms/step - loss: 0.2557 - accuracy: 0.9250 - val_loss: 0.3394 - val_accuracy: 0.9219 - lr: 4.0000e-05\n",
      "Epoch 132/200\n",
      "85/85 [==============================] - 19s 218ms/step - loss: 0.2537 - accuracy: 0.9257 - val_loss: 0.3381 - val_accuracy: 0.9220 - lr: 4.0000e-05\n",
      "Epoch 133/200\n",
      "85/85 [==============================] - 19s 221ms/step - loss: 0.2521 - accuracy: 0.9264 - val_loss: 0.3367 - val_accuracy: 0.9217 - lr: 4.0000e-05\n",
      "Epoch 134/200\n",
      "85/85 [==============================] - 20s 224ms/step - loss: 0.2493 - accuracy: 0.9270 - val_loss: 0.3360 - val_accuracy: 0.9235 - lr: 4.0000e-05\n",
      "Epoch 135/200\n",
      "85/85 [==============================] - 19s 224ms/step - loss: 0.2897 - accuracy: 0.9181 - val_loss: 0.4021 - val_accuracy: 0.9107 - lr: 4.0000e-05\n",
      "Epoch 136/200\n",
      "85/85 [==============================] - 19s 219ms/step - loss: 0.3673 - accuracy: 0.9035 - val_loss: 0.3813 - val_accuracy: 0.9083 - lr: 4.0000e-05\n",
      "Epoch 137/200\n",
      "85/85 [==============================] - 19s 220ms/step - loss: 0.2977 - accuracy: 0.9186 - val_loss: 0.3634 - val_accuracy: 0.9102 - lr: 4.0000e-05\n",
      "Epoch 138/200\n",
      "85/85 [==============================] - 19s 219ms/step - loss: 0.2776 - accuracy: 0.9231 - val_loss: 0.3497 - val_accuracy: 0.9159 - lr: 4.0000e-05\n",
      "Epoch 139/200\n",
      "85/85 [==============================] - 19s 222ms/step - loss: 0.2679 - accuracy: 0.9245 - val_loss: 0.3620 - val_accuracy: 0.9139 - lr: 4.0000e-05\n",
      "Epoch 140/200\n",
      "85/85 [==============================] - 19s 224ms/step - loss: 0.2741 - accuracy: 0.9236 - val_loss: 0.3355 - val_accuracy: 0.9161 - lr: 4.0000e-05\n",
      "Epoch 141/200\n",
      "85/85 [==============================] - 19s 214ms/step - loss: 0.2729 - accuracy: 0.9246 - val_loss: 0.3589 - val_accuracy: 0.9170 - lr: 4.0000e-05\n",
      "Epoch 142/200\n",
      "85/85 [==============================] - 19s 213ms/step - loss: 0.2622 - accuracy: 0.9265 - val_loss: 0.3141 - val_accuracy: 0.9233 - lr: 4.0000e-05\n",
      "Epoch 143/200\n",
      "85/85 [==============================] - 19s 213ms/step - loss: 0.2553 - accuracy: 0.9273 - val_loss: 0.3230 - val_accuracy: 0.9211 - lr: 4.0000e-05\n",
      "Epoch 144/200\n",
      "85/85 [==============================] - 19s 221ms/step - loss: 0.2990 - accuracy: 0.9225 - val_loss: 0.6582 - val_accuracy: 0.8569 - lr: 4.0000e-05\n",
      "Epoch 145/200\n",
      "85/85 [==============================] - 19s 224ms/step - loss: 0.3208 - accuracy: 0.9228 - val_loss: 0.4096 - val_accuracy: 0.9100 - lr: 4.0000e-05\n",
      "Epoch 146/200\n",
      "85/85 [==============================] - 19s 221ms/step - loss: 0.2945 - accuracy: 0.9263 - val_loss: 0.3751 - val_accuracy: 0.9178 - lr: 4.0000e-05\n",
      "Epoch 147/200\n",
      "85/85 [==============================] - 19s 215ms/step - loss: 0.2850 - accuracy: 0.9271 - val_loss: 0.3637 - val_accuracy: 0.9198 - lr: 4.0000e-05\n",
      "Epoch 148/200\n",
      "85/85 [==============================] - 19s 218ms/step - loss: 0.2772 - accuracy: 0.9281 - val_loss: 0.3622 - val_accuracy: 0.9178 - lr: 4.0000e-05\n",
      "Epoch 149/200\n",
      "85/85 [==============================] - 20s 225ms/step - loss: 0.2910 - accuracy: 0.9252 - val_loss: 0.3256 - val_accuracy: 0.9193 - lr: 4.0000e-05\n",
      "Epoch 150/200\n",
      "85/85 [==============================] - 20s 224ms/step - loss: 0.2766 - accuracy: 0.9274 - val_loss: 0.3280 - val_accuracy: 0.9235 - lr: 4.0000e-05\n",
      "Epoch 151/200\n",
      "85/85 [==============================] - 19s 217ms/step - loss: 0.3286 - accuracy: 0.9080 - val_loss: 0.3531 - val_accuracy: 0.9133 - lr: 4.0000e-05\n",
      "Epoch 152/200\n",
      "85/85 [==============================] - 19s 219ms/step - loss: 0.2885 - accuracy: 0.9189 - val_loss: 0.3322 - val_accuracy: 0.9172 - lr: 4.0000e-05\n",
      "Epoch 153/200\n",
      "85/85 [==============================] - 19s 214ms/step - loss: 0.2707 - accuracy: 0.9249 - val_loss: 0.3347 - val_accuracy: 0.9180 - lr: 4.0000e-05\n",
      "Epoch 154/200\n",
      "85/85 [==============================] - 20s 221ms/step - loss: 0.2629 - accuracy: 0.9276 - val_loss: 0.3394 - val_accuracy: 0.9213 - lr: 4.0000e-05\n",
      "Epoch 155/200\n",
      "85/85 [==============================] - 20s 224ms/step - loss: 0.2572 - accuracy: 0.9286 - val_loss: 0.3300 - val_accuracy: 0.9213 - lr: 4.0000e-05\n",
      "Epoch 156/200\n",
      "85/85 [==============================] - 19s 218ms/step - loss: 0.2553 - accuracy: 0.9295 - val_loss: 0.4426 - val_accuracy: 0.8970 - lr: 4.0000e-05\n",
      "Epoch 157/200\n",
      "85/85 [==============================] - 19s 213ms/step - loss: 0.2616 - accuracy: 0.9280 - val_loss: 0.3226 - val_accuracy: 0.9167 - lr: 4.0000e-05\n",
      "Epoch 158/200\n",
      "85/85 [==============================] - 19s 219ms/step - loss: 0.2556 - accuracy: 0.9303 - val_loss: 0.3251 - val_accuracy: 0.9200 - lr: 4.0000e-05\n",
      "Epoch 159/200\n",
      "85/85 [==============================] - 19s 217ms/step - loss: 0.2468 - accuracy: 0.9314 - val_loss: 0.3284 - val_accuracy: 0.9231 - lr: 4.0000e-05\n",
      "Epoch 160/200\n",
      "85/85 [==============================] - 19s 219ms/step - loss: 0.2426 - accuracy: 0.9321 - val_loss: 0.3263 - val_accuracy: 0.9235 - lr: 4.0000e-05\n",
      "Epoch 161/200\n",
      "85/85 [==============================] - 20s 218ms/step - loss: 0.3185 - accuracy: 0.9213 - val_loss: 0.4117 - val_accuracy: 0.9043 - lr: 4.0000e-05\n",
      "Epoch 162/200\n",
      "85/85 [==============================] - 19s 214ms/step - loss: 0.4610 - accuracy: 0.8525 - val_loss: 0.5233 - val_accuracy: 0.8394 - lr: 4.0000e-05\n",
      "Epoch 163/200\n",
      "85/85 [==============================] - 19s 213ms/step - loss: 0.4097 - accuracy: 0.8629 - val_loss: 0.4428 - val_accuracy: 0.8600 - lr: 4.0000e-05\n",
      "Epoch 164/200\n",
      "85/85 [==============================] - 19s 220ms/step - loss: 0.3731 - accuracy: 0.8738 - val_loss: 0.4295 - val_accuracy: 0.8713 - lr: 4.0000e-05\n",
      "Epoch 165/200\n",
      "85/85 [==============================] - 20s 227ms/step - loss: 0.3621 - accuracy: 0.8825 - val_loss: 0.4308 - val_accuracy: 0.8744 - lr: 4.0000e-05\n",
      "Epoch 166/200\n",
      "85/85 [==============================] - 19s 222ms/step - loss: 0.3431 - accuracy: 0.8881 - val_loss: 0.4007 - val_accuracy: 0.8850 - lr: 4.0000e-05\n",
      "Epoch 167/200\n",
      "85/85 [==============================] - 19s 219ms/step - loss: 0.3300 - accuracy: 0.8917 - val_loss: 0.3970 - val_accuracy: 0.8893 - lr: 4.0000e-05\n",
      "Epoch 168/200\n",
      "85/85 [==============================] - 19s 217ms/step - loss: 0.3206 - accuracy: 0.8956 - val_loss: 0.3893 - val_accuracy: 0.8939 - lr: 4.0000e-05\n",
      "Epoch 169/200\n",
      "85/85 [==============================] - 19s 218ms/step - loss: 0.3127 - accuracy: 0.8988 - val_loss: 0.3866 - val_accuracy: 0.8948 - lr: 4.0000e-05\n",
      "Epoch 170/200\n",
      "85/85 [==============================] - 19s 224ms/step - loss: 0.3053 - accuracy: 0.9018 - val_loss: 0.3771 - val_accuracy: 0.8998 - lr: 4.0000e-05\n",
      "Epoch 171/200\n",
      "85/85 [==============================] - 19s 218ms/step - loss: 0.2989 - accuracy: 0.9055 - val_loss: 0.3728 - val_accuracy: 0.9041 - lr: 4.0000e-05\n",
      "Epoch 172/200\n",
      "85/85 [==============================] - 19s 219ms/step - loss: 0.2924 - accuracy: 0.9093 - val_loss: 0.3683 - val_accuracy: 0.9059 - lr: 4.0000e-05\n",
      "Epoch 173/200\n",
      "85/85 [==============================] - 19s 214ms/step - loss: 0.2871 - accuracy: 0.9119 - val_loss: 0.3677 - val_accuracy: 0.9089 - lr: 4.0000e-05\n",
      "Epoch 174/200\n",
      "85/85 [==============================] - 19s 218ms/step - loss: 0.2816 - accuracy: 0.9144 - val_loss: 0.3610 - val_accuracy: 0.9104 - lr: 4.0000e-05\n",
      "Epoch 175/200\n",
      "85/85 [==============================] - 20s 220ms/step - loss: 0.2765 - accuracy: 0.9169 - val_loss: 0.3597 - val_accuracy: 0.9109 - lr: 4.0000e-05\n",
      "Epoch 176/200\n",
      "85/85 [==============================] - 20s 229ms/step - loss: 0.2723 - accuracy: 0.9192 - val_loss: 0.3592 - val_accuracy: 0.9117 - lr: 4.0000e-05\n",
      "Epoch 177/200\n",
      "85/85 [==============================] - 19s 219ms/step - loss: 0.2665 - accuracy: 0.9216 - val_loss: 0.3565 - val_accuracy: 0.9130 - lr: 4.0000e-05\n",
      "Epoch 178/200\n",
      "85/85 [==============================] - 19s 218ms/step - loss: 0.2624 - accuracy: 0.9234 - val_loss: 0.3540 - val_accuracy: 0.9141 - lr: 4.0000e-05\n",
      "Epoch 179/200\n",
      "85/85 [==============================] - 19s 214ms/step - loss: 0.2587 - accuracy: 0.9247 - val_loss: 0.3524 - val_accuracy: 0.9176 - lr: 4.0000e-05\n",
      "Epoch 180/200\n",
      "85/85 [==============================] - 19s 223ms/step - loss: 0.2548 - accuracy: 0.9261 - val_loss: 0.3502 - val_accuracy: 0.9181 - lr: 4.0000e-05\n",
      "Epoch 181/200\n",
      "85/85 [==============================] - 20s 219ms/step - loss: 0.2507 - accuracy: 0.9269 - val_loss: 0.3476 - val_accuracy: 0.9189 - lr: 4.0000e-05\n",
      "Epoch 182/200\n",
      "85/85 [==============================] - 19s 219ms/step - loss: 0.2884 - accuracy: 0.9190 - val_loss: 0.4273 - val_accuracy: 0.8965 - lr: 4.0000e-05\n",
      "Epoch 183/200\n",
      "85/85 [==============================] - 19s 215ms/step - loss: 0.2867 - accuracy: 0.9204 - val_loss: 0.3360 - val_accuracy: 0.9180 - lr: 4.0000e-05\n",
      "Epoch 184/200\n",
      "85/85 [==============================] - 19s 222ms/step - loss: 0.2680 - accuracy: 0.9251 - val_loss: 0.3525 - val_accuracy: 0.9169 - lr: 4.0000e-05\n",
      "Epoch 185/200\n",
      "85/85 [==============================] - 20s 226ms/step - loss: 0.2568 - accuracy: 0.9255 - val_loss: 0.3358 - val_accuracy: 0.9233 - lr: 4.0000e-05\n",
      "Epoch 186/200\n",
      "85/85 [==============================] - 20s 225ms/step - loss: 0.2454 - accuracy: 0.9292 - val_loss: 0.3347 - val_accuracy: 0.9233 - lr: 4.0000e-05\n",
      "Epoch 187/200\n",
      "85/85 [==============================] - 19s 223ms/step - loss: 0.2406 - accuracy: 0.9308 - val_loss: 0.3235 - val_accuracy: 0.9256 - lr: 4.0000e-05\n",
      "Epoch 188/200\n",
      "85/85 [==============================] - 19s 218ms/step - loss: 0.2365 - accuracy: 0.9312 - val_loss: 0.3355 - val_accuracy: 0.9243 - lr: 4.0000e-05\n",
      "Epoch 189/200\n",
      "85/85 [==============================] - 19s 214ms/step - loss: 0.2331 - accuracy: 0.9312 - val_loss: 0.3457 - val_accuracy: 0.9235 - lr: 4.0000e-05\n",
      "Epoch 190/200\n",
      "85/85 [==============================] - 19s 219ms/step - loss: 0.2342 - accuracy: 0.9315 - val_loss: 0.3307 - val_accuracy: 0.9230 - lr: 4.0000e-05\n",
      "Epoch 191/200\n",
      "85/85 [==============================] - 20s 221ms/step - loss: 0.2302 - accuracy: 0.9334 - val_loss: 0.3190 - val_accuracy: 0.9281 - lr: 4.0000e-05\n",
      "Epoch 192/200\n",
      "85/85 [==============================] - 19s 221ms/step - loss: 0.2535 - accuracy: 0.9295 - val_loss: 0.4147 - val_accuracy: 0.9083 - lr: 4.0000e-05\n",
      "Epoch 193/200\n",
      "85/85 [==============================] - 19s 217ms/step - loss: 0.2551 - accuracy: 0.9312 - val_loss: 0.3223 - val_accuracy: 0.9237 - lr: 4.0000e-05\n",
      "Epoch 194/200\n",
      "85/85 [==============================] - 19s 220ms/step - loss: 0.2475 - accuracy: 0.9318 - val_loss: 0.3064 - val_accuracy: 0.9272 - lr: 4.0000e-05\n",
      "Epoch 195/200\n",
      "85/85 [==============================] - 19s 215ms/step - loss: 0.2295 - accuracy: 0.9347 - val_loss: 0.3111 - val_accuracy: 0.9244 - lr: 4.0000e-05\n",
      "Epoch 196/200\n",
      "85/85 [==============================] - 20s 228ms/step - loss: 0.2223 - accuracy: 0.9353 - val_loss: 0.3119 - val_accuracy: 0.9257 - lr: 4.0000e-05\n",
      "Epoch 197/200\n",
      "85/85 [==============================] - 20s 225ms/step - loss: 0.2188 - accuracy: 0.9358 - val_loss: 0.3152 - val_accuracy: 0.9252 - lr: 4.0000e-05\n",
      "Epoch 198/200\n",
      "85/85 [==============================] - 19s 218ms/step - loss: 0.2167 - accuracy: 0.9361 - val_loss: 0.3088 - val_accuracy: 0.9265 - lr: 4.0000e-05\n",
      "Epoch 199/200\n",
      "85/85 [==============================] - 19s 214ms/step - loss: 0.2147 - accuracy: 0.9369 - val_loss: 0.3120 - val_accuracy: 0.9280 - lr: 4.0000e-05\n",
      "Epoch 200/200\n",
      "85/85 [==============================] - 19s 216ms/step - loss: 0.2125 - accuracy: 0.9375 - val_loss: 0.3157 - val_accuracy: 0.9291 - lr: 4.0000e-05\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "INITIAL_LR = 0.001\n",
    "LR_BREAKPOINTS = [50, 100, 200, 250]\n",
    "\n",
    "def custom_lr_scheduler(epoch, lr):\n",
    "    if epoch in LR_BREAKPOINTS:\n",
    "        return lr / 5\n",
    "    return lr\n",
    "\n",
    "log_dir = 'training-logs'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "scheduler = keras.callbacks.LearningRateScheduler(custom_lr_scheduler)\n",
    "\n",
    "hist = model.fit(train.batch(BATCH_SIZE), epochs=200, validation_data=test.batch(BATCH_SIZE), callbacks=[scheduler, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet50_eurosat_model_lr_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet-50/resnet50_eurosat_model_lr_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet-50/resnet50_eurosat_model_lr_2/assets\n",
      "C:\\Users\\Niels\\.virtualenvs\\uc-landcover-types--9lkH9oZ\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "C:\\Users\\Niels\\.virtualenvs\\uc-landcover-types--9lkH9oZ\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "\n",
    "model.save(f'resnet-50/{model_name}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save history\n",
    "pd.DataFrame(hist.history).to_csv(f'resnet-50/{model_name}/history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sns.set_theme()\n",
    "results_df = pd.read_csv(f'resnet-50/{model_name}/history.csv')\n",
    "\n",
    "sns.lineplot(x=results_df.index, y=results_df['accuracy'])\n",
    "sns.lineplot(x=results_df.index, y=results_df['val_accuracy'])\n",
    "plt.ylim(0.3,1.0)\n",
    "plt.yticks(np.arange(0.3, 1.1, step=0.1))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.title('Accuracy over epochs on EUROSAT dataset')\n",
    "plt.savefig(f'resnet-50/{model_name}/resnet50_accuracy.pdf')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f159b07f9c8f87ebde4fc74b8705cd6d307a0a898325bf84804e0259e571b916"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('uc-landcover-types--9lkH9oZ': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
